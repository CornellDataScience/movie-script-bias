{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815f51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39770d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/mei/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf53bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'frozen.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/45/dpnnlpm17dd5pmjw8jy6x7440000gn/T/ipykernel_2363/963503842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPDFfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'frozen.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpdfFileObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpdfReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfFileObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'frozen.pdf'"
     ]
    }
   ],
   "source": [
    "# Open the pdf file\n",
    "\n",
    "PDFfilename = 'frozen.pdf' \n",
    "\n",
    "pdfFileObj = open(PDFfilename, 'rb') \n",
    "\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "\n",
    "#script = PyPDF2.PdfFileReader(r\"/Users/mei/Downloads/frozen.pdf\")\n",
    "\n",
    "#numPages = script.getNumPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9d21f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "\n",
    "def gender_features(word):\n",
    "    \"\"\" feature extractor for the name classifier\n",
    "    The feature evaluated here is the last letter of a name\n",
    "    feature name - \"last_letter\"\n",
    "    \"\"\"\n",
    "    return {\"last_letter\": word[-1]}  # feature set\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Starting block \"\"\"\n",
    "\n",
    "    # Extract the data sets\n",
    "    labeled_names = ([(name, \"male\") for name in names.words(\"male.txt\")] +\n",
    "                     [(name, \"female\") for name in names.words(\"female.txt\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a27aee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7944\n"
     ]
    }
   ],
   "source": [
    "print(len(labeled_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2ff935",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64716b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [(gender_features(n), gender)\n",
    "                    for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c478618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the feature sets into training and test sets\n",
    "train_set, test_set = feature_sets[500:], feature_sets[:500]\n",
    "\n",
    "# Train the naiveBayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fae6a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "female\n"
     ]
    }
   ],
   "source": [
    " # Test out the classifier with few samples outside of training set\n",
    "print(classifier.classify(gender_features(\"neo\")))  # returns male\n",
    "print(classifier.classify(gender_features(\"trinity\")))  # returns female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "339a26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4c44d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'k'              male : female =     44.9 : 1.0\n",
      "             last_letter = 'a'            female : male   =     35.7 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.5 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba93fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract names in scene and add to list\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from io import StringIO\n",
    "\n",
    "from nameparser.parser import HumanName\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "person_list = []\n",
    "person_names=person_list\n",
    "def get_human_names(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    sentt = nltk.ne_chunk(pos, binary = False)\n",
    "\n",
    "    person = []\n",
    "    name = \"\"\n",
    "    for subtree in sentt.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
    "        for leaf in subtree.leaves():\n",
    "            person.append(leaf[0])\n",
    "        #if len(person) > 1: #avoid grabbing lone surnames\n",
    "        for part in person:\n",
    "            name += part + ' '\n",
    "            #if name[:-1] not in person_list:\n",
    "            person_list.append(name[:-1])\n",
    "            #name = ''\n",
    "        #person = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f81013ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT. CHURCH CHAPEL -- DAY \n",
      " \n",
      "   Elsa stands at the alter. Anna stands off to one side. She \n",
      "   peeks out to the audience. \n",
      " \n",
      "   Hans waves at her from the pews. He's changed his clothes. \n",
      " \n",
      "   The crown is placed on Elsa's head. The scepter and orb are \n",
      "   presented to Elsa on a pillow. She slowly reaches for them. \n",
      " \n",
      "                            BISHOP \n",
      "                      (a whisper) \n",
      "                  Your Majesty, the gloves. \n",
      " \n",
      "   Elsa hesitates. She breathes nervously, removes her gloves, \n",
      "   places them on the pillow. Her hands shake. She takes the orb \n",
      "   and scepter, then turns to the people. \n",
      " \n",
      "                            BISHOP (CONT'D) \n",
      "                      (formal, in Old Norse) \n",
      "                  Sehm hon HELL-drr IN-um HELL-gum \n",
      "                  AYG-num ok krund ee THES-um HELL- \n",
      "                  gah STAHTH, ehk teh frahm FUR-ear U- \n",
      "                  thear... \n",
      "                                                               20 \n",
      "FROZEN - J. Lee \n",
      " \n",
      " \n",
      " \n",
      "   The scepter and orb start to freeze over. \n",
      " \n",
      "                            BISHOP (CONT'D) \n",
      "                  ...Queen Elsa of Arendelle. \n",
      " \n",
      "                            CROWD \n",
      "                  Queen Elsa of Arendelle. \n",
      " \n",
      "   Just in time. Elsa manages to set the orb and scepter back \n",
      "   down on the pillow before anyone notices the ice. She picks \n",
      "   up her gloves and slips them on. She made it. \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('frozen.txt','r')\n",
    "text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d211a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anna', 'Anna', 'Elsa', 'Anna', 'Elsa', 'Elsa', 'Anna', 'Elsa', 'Elsa', 'Elsa']\n"
     ]
    }
   ],
   "source": [
    "names = get_human_names(text)\n",
    "\n",
    "for person in person_list:\n",
    "    person_split = person.split(\" \")\n",
    "    for name in person_split:\n",
    "        if wordnet.synsets(name):\n",
    "            #if(name in person_names):\n",
    "                #person_names.remove(person)\n",
    "                break\n",
    "\n",
    "scene_names = person_list[-1].split()\n",
    "\n",
    "print(scene_names)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a30df6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds one when female name is followed by another female name\n",
    "def interactions(l):\n",
    "    counthehe = 0\n",
    "    countpls = 0\n",
    "    for i in l:\n",
    "        if classifier.classify(gender_features(i)) == \"female\" : \n",
    "            if classifier.classify(gender_features(l[counthehe + 1])) == \"female\" : \n",
    "                if i != l[counthehe + 1] :\n",
    "                    countpls += 1\n",
    "        counthehe = counthehe + 1\n",
    "        if counthehe == len(l)-1 :\n",
    "            break\n",
    "    return countpls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ff78adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactionsCount = interactions(scene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eba4fa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(interactionsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db78fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
